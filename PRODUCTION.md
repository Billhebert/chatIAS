# üöÄ ChatIAS - Guia de Produ√ß√£o

Este documento descreve como usar o ChatIAS em **ambiente de produ√ß√£o**.

## ‚ö†Ô∏è Importante

- **PRODU√á√ÉO**: `chat.js` e `production-example.js`
- **DESENVOLVIMENTO/TESTES**: `chat-standalone.js` e `examples/demo-modular-system.js`

## üìã Pr√©-requisitos

### Obrigat√≥rios

1. **Node.js 18+**
```bash
node --version  # v18.0.0 ou superior
```

2. **OpenCode CLI**
```bash
npm install -g @opencode-ai/cli
opencode --version
```

3. **Depend√™ncias do projeto**
```bash
npm install
```

### Opcionais (mas recomendados)

4. **Ollama** (para fallback)
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Baixar modelos
ollama pull llama3.2
ollama pull qwen2.5-coder
ollama pull deepseek-coder-v2
```

## üîß Configura√ß√£o

### 1. Vari√°veis de Ambiente

Crie arquivo `.env`:

```env
# OpenCode SDK (obrigat√≥rio)
SDK_PORT=4096

# Ollama (opcional - apenas para fallback)
OLLAMA_URL=http://localhost:11434

# API Keys (se necess√°rio para providers)
OPENROUTER_API_KEY=sk-or-v1-...
```

### 2. Configura√ß√£o OpenCode

Edite `.opencode/config.json` conforme necess√°rio:

```json
{
  "model": {
    "provider": "opencode",
    "model": "minimax-m2.1-free"
  },
  "agent": {
    "chat": {
      "enabled": true
    }
  }
}
```

## üöÄ Execu√ß√£o em Produ√ß√£o

### Modo 1: Script Standalone

```bash
node chat.js
```

**Este √© o modo principal de produ√ß√£o**. Inclui:
- ‚úÖ 12 modelos remotos
- ‚úÖ 3 modelos Ollama (fallback)
- ‚úÖ Sistema modular completo
- ‚úÖ Todas as funcionalidades

### Modo 2: Como M√≥dulo

```javascript
import { ProductionChatClient } from "./production-example.js";

async function main() {
  const client = new ProductionChatClient({
    sdkPort: 4096
  });

  try {
    // Inicializar
    await client.initialize();

    // Criar sess√£o
    const sessionId = await client.createSession("Minha App");

    // Enviar mensagem
    const response = await client.sendMessage("Ol√°!");

    if (response.success) {
      console.log("Resposta:", response.data);
      console.log("Fonte:", response.source); // "remote" ou "ollama"
    }

    // Encerrar
    await client.shutdown();
  } catch (error) {
    console.error("Erro:", error);
    await client.shutdown();
  }
}

main();
```

## üìä Monitoramento

### Logs

Os logs incluem:
- ‚úÖ Status de inicializa√ß√£o
- ‚úÖ Tentativas de modelos
- ‚úÖ Sucessos e falhas
- ‚úÖ Tempo de resposta (em metadata Ollama)

### M√©tricas

Acesse informa√ß√µes do sistema:

```javascript
// Status dos agentes
const agentes = globalAgentManager.list({ enabled: true });
console.log(`Agentes ativos: ${agentes.length}`);

// Status das tools
const tools = globalToolRegistry.list(true);
console.log(`Tools ativas: ${tools.length}`);

// Status dos MCP servers
const mcps = globalMCPManager.list(true);
console.log(`MCP servers: ${mcps.length}`);
```

## üîÑ Fluxo de Fallback

```
1. Modelo prim√°rio especificado (se houver)
   ‚Üì falhou?
2. Modelo OpenCode 1 (minimax-m2.1-free)
   ‚Üì falhou?
3. Modelo OpenCode 2 (glm-4.7-free)
   ‚Üì falhou?
4. Modelos OpenRouter (7 modelos)
   ‚Üì falharam?
5. Modelos Zenmux (3 modelos)
   ‚Üì falharam?
6. ü¶ô Ollama modelo 1 (llama3.2)
   ‚Üì falhou?
7. ü¶ô Ollama modelo 2 (qwen2.5-coder)
   ‚Üì falhou?
8. ü¶ô Ollama modelo 3 (deepseek-coder-v2)
   ‚Üì falhou?
9. ‚ùå Retorna erro
```

## üõ°Ô∏è Tratamento de Erros

### Erros Fatais

O sistema lan√ßa erros em casos fatais:

```javascript
try {
  await client.initialize();
} catch (error) {
  if (error.message.includes("OpenCode SDK n√£o inicializado")) {
    // SDK n√£o est√° dispon√≠vel
    console.error("Instale OpenCode CLI:");
    console.error("npm install -g @opencode-ai/cli");
    process.exit(1);
  }
}
```

### Fallback Gracioso

Quando um modelo falha, o sistema:
1. Loga o erro
2. Tenta pr√≥ximo modelo automaticamente
3. Continua at√© Ollama
4. S√≥ retorna erro se TUDO falhar

## üîê Seguran√ßa

### API Keys

**NUNCA** commite API keys:

```bash
# .gitignore j√° inclui
.env
*.key
```

Configure via vari√°veis de ambiente:

```javascript
// No c√≥digo
const apiKey = process.env.OPENROUTER_API_KEY;
```

### Rate Limiting

Os providers t√™m rate limits. O fallback autom√°tico ajuda a distribuir carga.

## üìà Performance

### Otimiza√ß√µes

1. **Timeout configur√°vel**: Ajuste `timeout` no createOpencode()
2. **Cache de sess√µes**: Reutilize sessionId
3. **Modelos mais r√°pidos primeiro**: Lista ordenada por velocidade

### Benchmarks T√≠picos

- Modelos remotos: 1-5s por resposta
- Ollama local: 2-30s (depende de GPU)
- Cria√ß√£o de sess√£o: <500ms

## üß™ Testes em Produ√ß√£o

### Health Check

```javascript
async function healthCheck() {
  const client = new ProductionChatClient();

  try {
    await client.initialize();
    await client.createSession("Health Check");

    const response = await client.sendMessage("ping");

    if (response.success) {
      console.log("‚úÖ Sistema OK");
      return true;
    }

    console.error("‚ùå Sistema com problemas");
    return false;
  } catch (error) {
    console.error("‚ùå Sistema down:", error);
    return false;
  } finally {
    await client.shutdown();
  }
}
```

## üìû Suporte

### Logs de Debug

Para debug detalhado, adicione:

```javascript
console.log("DEBUG:", JSON.stringify(response, null, 2));
```

### Reportar Problemas

1. Colete logs completos
2. Inclua vers√µes (Node, OpenCode, Ollama)
3. Descreva comportamento esperado vs atual
4. Abra issue: https://github.com/Billhebert/chatIAS/issues

## üö® Troubleshooting

Veja [TROUBLESHOOTING.md](TROUBLESHOOTING.md) para problemas comuns.

## üìö Documenta√ß√£o Adicional

- [README.md](README.md) - Vis√£o geral
- [QUICKSTART.md](QUICKSTART.md) - In√≠cio r√°pido
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - Solu√ß√£o de problemas
- [OpenCode Docs](https://opencode.ai/docs/)
- [Ollama Docs](https://ollama.ai/)

## üìù Checklist de Deploy

- [ ] Node.js 18+ instalado
- [ ] OpenCode CLI instalado e rodando
- [ ] Ollama instalado (opcional)
- [ ] Depend√™ncias instaladas (`npm install`)
- [ ] `.env` configurado
- [ ] `.opencode/config.json` revisado
- [ ] Health check passou
- [ ] Logs configurados
- [ ] Monitoramento ativo

## üéØ Pr√≥ximos Passos

1. Configure seu ambiente seguindo este guia
2. Execute health check
3. Integre em sua aplica√ß√£o
4. Configure monitoramento
5. Deploy! üöÄ
