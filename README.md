# ChatIAS

Sistema de chat inteligente com mÃºltiplos modelos de IA e fallback Ollama, usando 100% do OpenCode SDK com arquitetura modular.

## ğŸš€ CaracterÃ­sticas

- âœ… **15 modelos de IA** (12 remotos + 3 Ollama)
- âœ… **Fallback em cascata** automÃ¡tico
- âœ… **Arquitetura modular** para agentes, tools e MCP servers
- âœ… **100% OpenCode SDK** - todas as funcionalidades
- âœ… **Ollama como Ãºltima opÃ§Ã£o** - privacidade e disponibilidade offline
- âœ… **Sistema de agentes** ativÃ¡vel/desativÃ¡vel
- âœ… **Tools customizadas** modulares
- âœ… **Suporte a MCP servers** (Model Context Protocol)
- âœ… **Skills** reutilizÃ¡veis

## ğŸ“¦ InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone https://github.com/Billhebert/chatIAS.git
cd chatIAS

# Instalar dependÃªncias
npm install

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Edite .env e configure SDK_PORT (padrÃ£o: 4096)
```

## ğŸ¦™ Configurar Ollama (Opcional mas Recomendado)

O Ollama funciona como fallback quando todos os modelos remotos falharem:

```bash
# 1. Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Baixar modelos
ollama pull llama3.2
ollama pull qwen2.5-coder
ollama pull deepseek-coder-v2

# 3. Verificar instalaÃ§Ã£o
ollama list
```

## ğŸ¯ Uso

### 3 Modos de ExecuÃ§Ã£o

#### 1. Modo Completo (com OpenCode SDK)
```bash
node chat.js
```
**Requisitos**: OpenCode CLI instalado e rodando
**Funcionalidades**: Todos os 15 modelos + sistema modular completo

#### 2. Modo Standalone (sem OpenCode SDK) - **Recomendado para testes**
```bash
node chat-standalone.js
```
**Requisitos**: Nenhum (Ollama opcional)
**Funcionalidades**: Sistema modular completo + Ollama

#### 3. Modo Demo (apenas demonstraÃ§Ã£o)
```bash
node examples/demo-modular-system.js
```
**Requisitos**: Nenhum
**Funcionalidades**: Demonstra todos os sistemas modulares

## ğŸ—ï¸ Arquitetura

### Estrutura de DiretÃ³rios

```
chatIAS/
â”œâ”€â”€ .opencode/               # ConfiguraÃ§Ãµes OpenCode
â”‚   â”œâ”€â”€ config.json         # Config principal
â”‚   â”œâ”€â”€ agent/              # Agentes modulares
â”‚   â”‚   â”œâ”€â”€ chat.md
â”‚   â”‚   â”œâ”€â”€ code-analyst.md
â”‚   â”‚   â”œâ”€â”€ code-writer.md
â”‚   â”‚   â”œâ”€â”€ researcher.md
â”‚   â”‚   â””â”€â”€ tester.md
â”‚   â””â”€â”€ skill/              # Skills reutilizÃ¡veis
â”‚       â”œâ”€â”€ ollama-integration/
â”‚       â”œâ”€â”€ multi-model-fallback/
â”‚       â””â”€â”€ sdk-usage/
â”œâ”€â”€ lib/                    # Bibliotecas modulares
â”‚   â”œâ”€â”€ agents/            # Sistema de agentes
â”‚   â”œâ”€â”€ ollama/            # Cliente Ollama
â”‚   â”œâ”€â”€ tools/             # Tools customizadas
â”‚   â””â”€â”€ mcp/               # Gerenciador MCP
â”œâ”€â”€ sdk/                   # OpenCode SDK
â”œâ”€â”€ chat.js               # AplicaÃ§Ã£o principal
â””â”€â”€ package.json
```

### Sistema de Fallback

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Modelo Especificado                  â”‚
â”‚    â†“ (falhou?)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Modelos OpenCode (2)                 â”‚
â”‚    - minimax-m2.1-free                  â”‚
â”‚    - glm-4.7-free                       â”‚
â”‚    â†“ (todos falharam?)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Modelos OpenRouter Free (7)          â”‚
â”‚    - kat-coder-pro                      â”‚
â”‚    - gemini-2.0-flash-exp               â”‚
â”‚    - qwen3-coder                        â”‚
â”‚    - devstral-2512                      â”‚
â”‚    - llama-3.3-70b-instruct             â”‚
â”‚    - devstral-small-2507                â”‚
â”‚    - glm-4.5-air                        â”‚
â”‚    â†“ (todos falharam?)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Modelos Zenmux (3)                   â”‚
â”‚    - mimo-v2-flash-free                 â”‚
â”‚    - glm-4.6v-flash-free                â”‚
â”‚    - kat-coder-pro-v1-free              â”‚
â”‚    â†“ (todos falharam?)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. ğŸ¦™ Ollama Local (3)                  â”‚
â”‚    - llama3.2                           â”‚
â”‚    - qwen2.5-coder                      â”‚
â”‚    - deepseek-coder-v2                  â”‚
â”‚    â†“ (todos falharam?)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âŒ Erro Final                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤– Agentes

### Agentes PrimÃ¡rios

- **chat** - Agente principal para conversas gerais
- **code-analyst** - Analisa cÃ³digo sem modificar (somente leitura)
- **code-writer** - Escreve e edita cÃ³digo

### Subagentes

- **researcher** - Pesquisa informaÃ§Ãµes na web e cÃ³digo
- **tester** - Executa e analisa testes

### Gerenciar Agentes

```javascript
import { globalAgentManager } from "./lib/agents/index.js";

// Listar agentes
globalAgentManager.list({ enabled: true });

// Habilitar/Desabilitar
globalAgentManager.enable("code-analyst");
globalAgentManager.disable("code-analyst");

// Configurar ferramentas
globalAgentManager.setTools("chat", {
  bash: "ask",
  edit: true
});
```

## ğŸ”§ Tools Customizadas

### Tools Ollama

- `ollama_generate` - Gera texto com Ollama
- `ollama_chat` - Chat usando Ollama
- `ollama_status` - Verifica status do Ollama

### Gerenciar Tools

```javascript
import { globalToolRegistry } from "./lib/tools/index.js";

// Executar tool
await globalToolRegistry.execute("ollama_status");

// Habilitar/Desabilitar
globalToolRegistry.enable("ollama_generate");
globalToolRegistry.disable("ollama_generate");

// Listar tools
globalToolRegistry.list(true); // apenas habilitadas
```

## ğŸ”Œ MCP Servers

Servidores MCP estendem funcionalidades atravÃ©s do Model Context Protocol.

### Gerenciar MCP

```javascript
import { globalMCPManager } from "./lib/mcp/index.js";

// Registrar servidor local
globalMCPManager.registerLocal("filesystem", {
  command: ["npx", "-y", "@modelcontextprotocol/server-filesystem"],
  args: ["/path/to/dir"],
  enabled: true
});

// Iniciar servidor
await globalMCPManager.startLocal("filesystem");

// Parar servidor
globalMCPManager.stopLocal("filesystem");

// Habilitar/Desabilitar
globalMCPManager.enable("filesystem");
globalMCPManager.disable("filesystem");
```

## ğŸ“š Skills

Skills sÃ£o instruÃ§Ãµes reutilizÃ¡veis em formato Markdown.

### Skills DisponÃ­veis

- **ollama-integration** - IntegraÃ§Ã£o com Ollama
- **multi-model-fallback** - Sistema de fallback
- **sdk-usage** - Guia completo do SDK

### Criar Nova Skill

```bash
mkdir -p .opencode/skill/my-skill
```

Crie `.opencode/skill/my-skill/SKILL.md`:

```markdown
---
name: my-skill
description: DescriÃ§Ã£o da skill
license: MIT
---

# Minha Skill

ConteÃºdo da skill aqui...
```

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### `.opencode/config.json`

```json
{
  "model": {
    "provider": "opencode",
    "model": "minimax-m2.1-free"
  },
  "agent": {
    "custom-agent": {
      "description": "Meu agente customizado",
      "mode": "primary",
      "temperature": 0.5,
      "tools": { "*": true }
    }
  },
  "tool": {
    "ollama": {
      "enabled": true,
      "priority": "fallback"
    }
  },
  "mcp": {
    "servers": {
      "my-server": {
        "type": "local",
        "command": ["npx", "my-mcp-server"],
        "enabled": true
      }
    }
  }
}
```

## ğŸ” VariÃ¡veis de Ambiente

Crie um arquivo `.env`:

```env
# OpenCode SDK
SDK_PORT=4096

# Ollama (opcional)
OLLAMA_URL=http://localhost:11434

# API Keys (se necessÃ¡rio)
OPENROUTER_API_KEY=sk-or-v1-...
```

## ğŸ§ª Testes

```bash
# Testar sistema completo
node chat.js

# Verificar Ollama
curl http://localhost:11434/api/tags
```

## ğŸ“– DocumentaÃ§Ã£o

- [OpenCode SDK](https://opencode.ai/docs/sdk/)
- [Agents](https://opencode.ai/docs/agents/)
- [Tools](https://opencode.ai/docs/tools/)
- [MCP Servers](https://opencode.ai/docs/mcp-servers/)
- [Skills](https://opencode.ai/docs/skills/)
- [Ollama](https://ollama.ai/)

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

ISC

## ğŸ‘¤ Autor

ChatIAS Project

## ğŸ™ Agradecimentos

- OpenCode.ai pela excelente SDK
- Ollama pelo framework de modelos locais
- Comunidade open source
